{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5184d6-a876-4932-98ee-32eed022d2f1",
   "metadata": {},
   "source": [
    "![](./images/Title.PNG)\n",
    "<div class=\"alert alert-block alert-info\"> <b> </b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc45ac9b-ff6d-4494-8a2a-58cc144af4d7",
   "metadata": {},
   "source": [
    "# Fraud detection from transactions\n",
    "![](./images/workflow_fraud.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e14a2ac-c887-4cc2-8d14-59c02a1fb9ef",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b> </b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce617147-6c1c-49d7-a689-23ae15689fa0",
   "metadata": {},
   "source": [
    "## 1 - Connect to Vantage\n",
    "<div class=\"alert alert-block alert-info\"> <b> </b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1191c5f8-65a5-454b-bbda-27a5e06dbab2",
   "metadata": {},
   "source": [
    "![](./images/Slide32.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48be49cf-c99f-49a0-9b6e-65dca5082f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'teradataml.options.display' from 'C:\\\\Users\\\\dm250067\\\\Anaconda3\\\\envs\\\\vantage39\\\\lib\\\\site-packages\\\\teradataml\\\\options\\\\display.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import teradataml as tdml\n",
    "tdml.options.configure.byom_install_location = \"mldb\"\n",
    "tdml.display.print_sqlmr_query = False\n",
    "import getpass\n",
    "import json\n",
    "tdml.__version__\n",
    "from datetime import datetime\n",
    "tic = datetime.now()\n",
    "tdml.options.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82424a5-65fb-4795-9c2e-427e59b18ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17.20.00.04'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdml.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5bcb716-c7a5-4c54-985c-5104a289a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aoa import (\n",
    "    record_training_stats,\n",
    "    save_plot,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9266811-6f73-4758-acb3-bfa40e558a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the local project repository for this model demo\n",
    "model_local_path = 'C:/Users/dm250067/OneDrive - Teradata/Documents/01 - Code Development/modelops-demo-models/model_definitions/transaction_fraud_indb'\n",
    "res = os.system(f'mkdir -p \"{model_local_path}\"')\n",
    "res = os.system(f'mkdir -p \"{model_local_path}/model_modules\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30baadf2-d62d-4ff4-9a88-595db218ce54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dm250067\\Anaconda3\\envs\\vantage39\\lib\\site-packages\\teradataml\\context\\context.py:480: TeradataMlRuntimeWarning: Warning: Password is URL encoded.\n",
      "  warnings.warn(\"Warning: Password is URL encoded.\", category=TeradataMlRuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Engine(teradatasql://:***@tdprd3.td.teradata.com/?DATABASE=ADLDSD_CHURN&LOGDATA=%2A%2A%2A&LOGMECH=%2A%2A%2A&USER=DM250067)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Param = {\n",
    "    'host'          : 'tdprd2.td.teradata.com', \n",
    "    'user'          : 'dm250067', \n",
    "    'password'      : \"ENCRYPTED_PASSWORD(file:{},file:{})\".format ('../../PassKey.properties','../../EncPass.properties'), #getpass.getpass(), \n",
    "    'logmech'       : 'LDAP',\n",
    "    'database'      : 'ADLSLSEMEA_DEMO_BANKING',\n",
    "    'temp_database_name' : 'dm250067'\n",
    "    }\n",
    "\n",
    "Param = {\n",
    "    'host'          : 'tdprd3.td.teradata.com', \n",
    "    'user'          : 'dm250067', \n",
    "    'password'      : \"ENCRYPTED_PASSWORD(file:{},file:{})\".format ('../../PassKey.properties','../../EncPass.properties'), #getpass.getpass(), \n",
    "    'logmech'       : 'LDAP',\n",
    "    'database'      : 'ADLDSD_CHURN',\n",
    "    'temp_database_name' : 'dm250067'\n",
    "    }\n",
    "\n",
    "tdml.create_context(**Param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf4c1a8-1ee3-4ea8-a3fa-1f0c3e0809cb",
   "metadata": {},
   "source": [
    "## 2 - Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20cccfd-b426-4f17-aa6e-2a3701b3e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $model_local_path/model_modules/training.py\n",
    "from teradataml import (\n",
    "    DataFrame,\n",
    "    GLM,\n",
    "    ScaleFit,\n",
    "    ScaleTransform,\n",
    "    DecisionForest\n",
    ")\n",
    "from aoa import (\n",
    "    record_training_stats,\n",
    "    save_plot,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_roc_curve(fi, img_filename):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    feat_importances = pd.Series(fi)\n",
    "    feat_importances.nlargest(10).plot(kind='barh').set_title('Feature Importance')\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def train(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name   = context.dataset_info.target_names[0]\n",
    "    entity_key    = context.dataset_info.entity_key\n",
    "\n",
    "    # read training dataset from Teradata and convert to pandas\n",
    "    train_df      = DataFrame.from_query(context.dataset_info.sql)\n",
    "\n",
    "    print (\"Scaling using InDB Functions...\")\n",
    "    \n",
    "    scaler = ScaleFit(\n",
    "        data           =train_df,\n",
    "        target_columns = feature_names,\n",
    "        scale_method   = context.hyperparams[\"scale_method\"],\n",
    "        miss_value     = context.hyperparams[\"miss_value\"],\n",
    "        global_scale   = context.hyperparams[\"global_scale\"].lower() in ['true', '1'],\n",
    "        multiplier     = context.hyperparams[\"multiplier\"],\n",
    "        intercept      = context.hyperparams[\"intercept\"]\n",
    "    )\n",
    "\n",
    "    scaled_train = ScaleTransform(\n",
    "        data           = train_df,\n",
    "        object         = scaler.output,\n",
    "        accumulate     = [target_name, entity_key]\n",
    "    )\n",
    "    \n",
    "    scaler.output.to_sql(f\"scaler_${context.model_version}\", if_exists=\"replace\")\n",
    "    print(\"Saved scaler\")\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "DecisionForest_obj = tdml.DecisionForest(data = ADS_scaled_training, \n",
    "                            input_columns = features, \n",
    "                            response_column = target, \n",
    "                            max_depth = 15, \n",
    "                            num_trees = 72, \n",
    "                            min_node_size = 1, \n",
    "                            mtry = 6, \n",
    "                            mtry_seed = 1, \n",
    "                            seed = 1, \n",
    "                            tree_type = 'CLASSIFICATION')\n",
    "    model = DecisionForest(\n",
    "        input_columns        = feature_names,\n",
    "        response_column      = target_name,\n",
    "        data                 = scaled_train.result,\n",
    "        max_depth            = context.hyperparams[\"max_depth\"],\n",
    "        num_trees            = context.hyperparams[\"num_trees\"],\n",
    "        min_node_size        = context.hyperparams[\"min_node_size\"],\n",
    "        mtry                 = context.hyperparams[\"mtry\"],\n",
    "        mtry_seed            = context.hyperparams[\"mtry_seed\"],\n",
    "        seed                 = context.hyperparams[\"seed\"],\n",
    "        tree_type            = 'CLASSIFICATION'\n",
    "    )\n",
    "    \n",
    "    model.result.to_sql(f\"model_${context.model_version}\", if_exists=\"replace\")    \n",
    "    print(\"Saved trained model\")\n",
    "\n",
    "    # Calculate feature importance and generate plot\n",
    "    model_pdf = model.result.to_pandas()[['predictor','estimate']]\n",
    "    predictor_dict = {}\n",
    "    \n",
    "    for index, row in model_pdf.iterrows():\n",
    "        if row['predictor'] in feature_names:\n",
    "            value = row['estimate']\n",
    "            predictor_dict[row['predictor']] = value\n",
    "    \n",
    "    feature_importance = dict(sorted(predictor_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    keys, values = zip(*feature_importance.items())\n",
    "    norm_values = (values-np.min(values))/(np.max(values)-np.min(values))\n",
    "    feature_importance = {keys[i]: float(norm_values[i]*1000) for i in range(len(keys))}\n",
    "    plot_feature_importance(feature_importance, f\"{context.artifact_output_path}/feature_importance\")\n",
    "\n",
    "    record_training_stats(\n",
    "        train_df,\n",
    "        features=feature_names,\n",
    "        targets=[target_name],\n",
    "        categorical=[target_name],\n",
    "        feature_importance=feature_importance,\n",
    "        context=context\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
